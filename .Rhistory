pwd
help
graph
graphs
x <- 911
print(x)
x <- 911L
print(x)
x.class
x
x <- 2:12
x
x <- c(.5, 0.6)
x
x <- c(5L, 0.6)
x
x <- a:f
x <- vector("string", 10)
x <- vector("integer", 10)
x
x <- vector("numeric", 10)
x
y <- c(1.7, "a")
y
y <- c(1.7, TRUE)
y
x <- 0:6
asLogical(x)
as.logical(x)
z <- as.logical(x)
z
z <- as.complex(x)
z
m <- matrix(nrow = 2, ncol = 4)
m
attributes(x)
attributes(m)
m <- matrix(2, 4, 5, 6, 7, 8, 9, 0, nrow = 2, ncol = 4)
m <- matrix(2, 4, 5, nrow = 2, ncol = 4)
m <- matrix(z, nrow = 2, ncol = 4)
z <- 0:8
m <- matrix(z, nrow = 2, ncol = 4)
z <- 0:7
m <- matrix(z, nrow = 2, ncol = 4)
m
dim(z) <- c(2,4)
z
x <- 2:12
y <- 5:15
z <- cbind(x, y)
z
z <- rbind(x, y)
z
z <- list(5L, "Lol", TRUE, 9.11)
z
z[1]
z[[1]]
z[[[1]]
z[[[1]]]
z[[1]]
x <- factor(c(2, 3, 2, 4, 2, 2))
x
table(x)
unclass(x)
x <- factor(c(2, 3, 2, 4, 2, 2), levels =  c(2, 3, 4))
x
x <- factor(c(2, 3, 2, 4, 2, 2), levels =  c(2, 3))
x
table(x)
x <- factor(c(2, 3, 2, 4, 2, 2), levels =  c(4, 2, 3))
unclass(x)
x <- data.frame(foo = 1:4, bar = (T, T, F, F))
x <- data.frame(foo = 1:4, bar = (TRUE, TRUE, FALSE, FALSE))
x <- data.frame(foo = 1:4, bar = c(TRUE, TRUE, FALSE, FALSE))
x
read.csv()
pwd
Andhra.Pradesh...Adilabad <- read.csv("~/program/GeneralElections2014Analysis/DataCollection/Andhra Pradesh - Adilabad.csv")
View(Andhra.Pradesh...Adilabad)
View(Andhra.Pradesh...Adilabad)
View(Andhra.Pradesh...Adilabad)
View(Andhra.Pradesh...Adilabad)
blrsouth <- read.csv("~/program/GeneralElections2014Analysis/DataCollection/Karnataka - Bangalore South.csv")
View(blrsouth)
names(blrsouth)
names(blrsouth) <- (1, 2, 3)
names(blrsouth) <- c(1, 2, 3)
blrsouth
clear
clear()
View(blrsouth)
blrsouth[1]
blrsouth[[1]
;
blrsouth[[1]]
blrsouth[1][3]
blrsouth[1][1]
blrsouth[1][2]
blrsouth[1:2]
blrsouth[1,2]
blrsouth[1,3]
blrsouth[2,3]
blrsouth[1,4]
blrsouth[1,1]
blrsouth[5,1]
levels(blrsouth)
blrsouth[5, , ]
blrsouth[5, , drop = FALSE]
blrsouth
blrsouth[5, , drop = FALSE]
m <- blrsouth[5, , drop = FALSE]
m
m[1,]
m[1]
x <- list(a = 1:2, b = 2:5)
x
x[1]
x[[1]]
x$foo
x$a
x$b
x[c(1, 2)]
View(blrsouth)
winner <- complete.cases(blrsouth)
winner
blrsouth[winner, ]
blrsouth[winner, ][1:5, ]
blrsouth[1:5, ]
blrsouth[1:5, ][winner, ]
blrsouth[1:5, ]
write.table(blrsouth)
write.csv(blrsouth)
classes <- sapply(blrsouth, class)
classes
dput(blrsouth)
dput(blrsouth, file = "a.R")
write.csv(blrsouth, file = "a.csv")
rm(classes)
rm(x, y, z)
write.csv(blrsouth, gzfile = "a.csv")
write.csv(blrsouth, file = "a.R")
for (i in 1:10) {}
for (i in 1:10) {print(i)}
for (i in 1:10) {print(blrsouth[i])}
for (i in 1:3) {print(blrsouth[[i]])}
for (i in blrsouth) {print(i)}
sd(blrsouth[3])
sd(blrsouth[3,])
f <- function(a, b = 0) {a^1.52}
f(3.25)
args(cat)
write.csv(blrsouth, file = "a.R")
source("a.R")
cube <- make.power(3)
cube(9)
ls(environment(cube))
ls(environment(make.power))
source("a.R")
f(3)
months
months(2014)
months(Sys.time())
Sys.time()
weeks(Sys.time())
week(Sys.time())
`0_Consolidated_Report` <- read.csv("~/0_Consolidated_Report.csv", header=F, quote="")
View(`0_Consolidated_Report`)
View(`0_Consolidated_Report`)
a <- 1:10
lapply(a, mean)
a <- list(a = 1:10)
lapply(a, mean)
sapply(a, mean)
cr <- read.csv("~/0_Consolidated_Report.csv", header=F, quote="")
View(cr)
apply(cr, 1, mean)
clear
apply(cr[5], 1, mean)
View(cr)
str(cr)
library(xml)
library(XML)
fileUrl <- "http://eciresults.nic.in/ConstituencywiseS1026.htm?ac=26"
doc <- htmlTreeParse(fileUrl, useInternal=TRUE)
install.packages("XML")
doc <- htmlTreeParse(fileUrl, useInternal=TRUE)
doc <- htmlTreeParse(fileUrl, useInternal=TRUE)
library(XML)
doc <- htmlTreeParse(fileUrl, useInternal=TRUE)
fileUrl <- "http://eciresults.nic.in/ConstituencywiseS1026.htm?ac=26"
doc <- htmlTreeParse(fileUrl, useInternal=TRUE)
doc
`0_Consolidated_Report` <- read.csv("~/0_Consolidated_Report.csv", header=F, quote="")
View(`0_Consolidated_Report`)
View(`0_Consolidated_Report`)
View(`0_Consolidated_Report`)
View(`0_Consolidated_Report`)
View(`0_Consolidated_Report`)
cr <- read.csv("~/0_Consolidated_Report.csv", header=F, quote="")
View(cr)
cr[[6]]
lapply(mean, cr[[6]])
lapply(mean, cr[[5]])
Group4Data <- read.csv("~/Documents/IIIT - B/3rd Semester/Data Analytics/project/Group4Data.csv")
View(Group4Data)
View(Group4Data)
NBtab
library(e1071)
index <- 1:nrow(Group4Data)
testindex <- sample(index, trunc(length(index)/3))
testrecords <- Group4Data[testindex,]
traindrecords <- Group4Data[-testindex,]
NBayes <- naiveBayes(traindrecords[,c(11, 12)],traindrecords[,17])
NBpred <- predict(NBayes , testrecords[,-17])
NBtab <- table(true = testrecords[,17], pred = NBpred)
NBtab
library(e1071)
index <- 1:nrow(Group4Data)
testindex <- sample(index, trunc(length(index)/3))
testrecords <- Group4Data[testindex,]
traindrecords <- Group4Data[-testindex,]
NBayes <- naiveBayes(traindrecords[,c(11, 12)],traindrecords[,29])
NBpred <- predict(NBayes , testrecords[,-29])
NBtab <- table(true = testrecords[,29], pred = NBpred)
NBtab
library(e1071)
index <- 1:nrow(Group4Data)
testindex <- sample(index, trunc(length(index)/3))
testrecords <- Group4Data[testindex,]
traindrecords <- Group4Data[-testindex,]
NBayes <- naiveBayes(traindrecords[,c(1, 4)],traindrecords[,29])
NBpred <- predict(NBayes , testrecords[,-29])
NBtab <- table(true = testrecords[,29], pred = NBpred)
NBtab
setwd("~/git/data_analytics")
library(stringr)
library(plyr)
library(MASS)
library(ISLR)
library(car)
# read the csv
sslc <- read.csv("data/Group4Data.csv")
# select the 8 columns that we are interested in
sslc.subset <- subset(sslc,
select=c("REG_NO", "L1_MARKS", "L2_MARKS", "L3_MARKS",
"S1_MARKS", "S2_MARKS", "S3_MARKS", "TOTAL_MARKS", "NRC_CLASS"))
# remove all the non numeric characters
nonNumericCharactersRemover <- function(x) {
x <- str_replace_all(x, pattern="[^0-9]", replacement="")
return(as.numeric(x))
}
sslc.subset <- data.frame(sslc.subset[1],
lapply(sslc.subset[2:8], nonNumericCharactersRemover),
sslc.subset[9])
# eliminate the unwanted rows
sslc.subset <- subset(sslc.subset, subset=(L1_MARKS <= 125 & L2_MARKS <= 100 & L3_MARKS <= 100 &
S1_MARKS <= 100 & S2_MARKS <= 100 & S3_MARKS <= 100 & TOTAL_MARKS <= 625))
# corelation matrix
marksCor <- cor(sslc.subset[2:8])
marksCor
# regression
sslc.fit <- lm(TOTAL_MARKS~.-REG_NO-NRC_CLASS, data=sslc.subset)
summary(sslc.fit)
summary(sslc.fit)$r.sq
# par(mfrow=c(2,2))
# plot(sslc.fit)
# variance inflation factors
vif(sslc.fit)
# prediction
sslc.topperdata = subset(sslc.subset, subset=(TOTAL_MARKS >= 615))
predict(sslc.fit, sslc.topperdata, interval="confidence") # see the confidence
predict(sslc.fit, sslc.topperdata, interval="prediction") # predict it
View(sslc.topperdata)
sslc.synergy <- lm(TOTAL_MARKS~.-REG_NO-NRC_CLASS+L1_MARKS*L2_MARKS*L3_MARKS*S1_MARKS*S2_MARKS*S3_MARKS, data=sslc.subset)
summary(sslc.synergy)$r.sq
summary(sslc.synergy)
sslc.classificationset <- sslc.subset
library(e1071)
index <- 1:nrow(sslc.classificationset)
testindex <- sample(index, trunc(length(index)/3))
testrecords <- sslc.classificationset[testindex,]
traindrecords <- sslc.classificationset[-testindex,]
# use all
NBayes.all <- naiveBayes(traindrecords[, 2:7],traindrecords[, 8])
NBpred.all <- predict(NBayes.all , testrecords[, -8])
NBtab.all <- table(true = testrecords[, 8], pred = NBpred.all)
# Use ones suggested by regression
NBayes.reg <- naiveBayes(traindrecords[, c(2, 3, 6, 7)],traindrecords[, 8])
NBpred.reg <- predict(NBayes.reg , testrecords[, -8])
NBayes.reg <- naiveBayes(traindrecords[, c(2, 3, 6, 7)],traindrecords[, 8])
NBpred.reg <- predict(NBayes.reg , testrecords[, -8])
sslc.classificationset <- data.frame(sslc.subset[1],
lapply(sslc.subset[2:7], roundOffMarks),
sslc.subset[9])
roundOffMarks <- function(x) {
return(as.numeric(round(x,digits=-1)))
}
# create a classification set
sslc.classificationset <- data.frame(sslc.subset[1],
lapply(sslc.subset[2:7], roundOffMarks),
sslc.subset[9])
index <- 1:nrow(sslc.classificationset)
testindex <- sample(index, trunc(length(index)/3))
testrecords <- sslc.classificationset[testindex,]
traindrecords <- sslc.classificationset[-testindex,]
NBayes.all <- naiveBayes(traindrecords[, 2:7],traindrecords[, 8])
NBpred.all <- predict(NBayes.all , testrecords[, -8])
NBtab.all <- table(true = testrecords[, 8], pred = NBpred.all)
library(caret)
confusionMatrix(NBtab.all)
NBayes.reg <- naiveBayes(traindrecords[, c(2, 3, 6, 7)],traindrecords[, 8])
NBpred.reg <- predict(NBayes.reg , testrecords[, -8])
NBtab.reg <- table(true = testrecords[, 8], pred = NBpred.reg)
NBayes.worst <- naiveBayes(traindrecords[, 5:6],traindrecords[, 8])
NBpred.worst <- predict(NBayes.worst , testrecords[, -8])
NBtab.worst <- table(true = testrecords[, 8], pred = NBpred.worst)
confusionMatrix(NBtab.worst)
confusionMatrix(NBtab.reg)
library(ISLR)
names(Smarket)
dim(Smarket)
summary(Smarket)
cor(Smarket)
cor(Smarket[, -9])
cor(Smarket[, -9])
attach(Smarket)
plot(Volume)
glm.fit= glm(formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, family = binomial, data = Smarket)
summary(glm.fit)
coef(glm.fit)
summary(glm.fit)$coef
summary(glm.fit)$coef[, 4]
glm.probs = predict(glm.fit, type = "response")
glm.probs
glm.probs[1:10]
contrasts(Direction)
glm.pred = rep("Down", 1250)
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction)
Direction
mean(glm.pred == Direction)
train = (Year < 2005)
Smarket.2005 = Smarket[!train]
Smarket.2005 = Smarket[!train, ]
View(Smarket.2005)
Direction.2005 = Direction[!train]
Direction.2005
glm.fit= glm(formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
family = binomial, data = Smarket, subset = train)
glm.probs = predict(glm.fit, Smarket.2005, type="response")
glm.pred = rep("Down", 252)
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction)
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
mean(glm.pred != Direction.2005)
glm.fit= glm(formula = Direction ~ Lag1 + Lag2,
family = binomial, data = Smarket, subset = train)
glm.probs = predict(glm.fit, Smarket.2005, type="response")
glm.pred = rep("Down", 252)
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
mean(glm.pred != Direction.2005)
predict(glm.fit, newdata = data.frame(Lag1 = c(1.2, 1.5), Lag2 = c(1.1, -0.8)), type = "response")
library(MASS)
lda.fit = lda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)
lda.fit
plot(lda.fit)
lda.pred = predict(lda.fit, Smarket.2005)
lda.pred
names(lda.pred)
lda.class = lda.pred$class
table(lda.class, Direction.2005)
mean(lda.class==Direction.2005)
sum(lda.pred$posterior[,1] >= 0.5)
sum(lda.pred$posterior[,1] < 0.5)
lda.pred$posterior[1:20, 1]
lda.class[1:20]
sum(lda.pred$posterior[,1] >= 0.9)
qda.fit = qda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)
qda.fit
plot(qda.fit)
qda.pred = predict(qda.fit, Smarket.2005)
names(qda.pred)
qda.class = qda.pred$class
table(qda.class, Direction.2005)
mean(qda.class==Direction.2005)
sum(qda.pred$posterior[,1] >= 0.5)
sum(qda.pred$posterior[,1] < 0.5)
qda.pred$posterior[1:20, 1]
qda.class[1:20]
sum(qda.pred$posterior[,1] >= 0.9)
library(class)
train.X = cbind(Lag1, Lag2) [train, ]
test.X = cbind(Lag1, Lag2) [!train, ]
train.Direction = Direction[train]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction, k = 1)
table(knn.pred, Direction.2005)
knn.pred = knn(train.X, test.X, train.Direction, k = 3)
table(knn.pred, Direction.2005)
q()
